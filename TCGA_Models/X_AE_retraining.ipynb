{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a76c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4128047bf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(1, '/home/wangc90/Data_integration/MOCSS/mocss/code/')\n",
    "import evaluation\n",
    "from Data_prep import DataSet_Prep, DataSet_construction\n",
    "from tsn_visulization import tsn_data, tsn_plot\n",
    "random.seed(2023)\n",
    "torch.manual_seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84d4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### variationalAE with concatenated inputs (X-VAE)\n",
    "### In order to train the variational autoencoder, we only \n",
    "### need to add the auxillary loss in our training algorithm\n",
    "\n",
    "class X_AE_Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        ### input dimension for omic 1, omic 2 and omic 3\n",
    "        self.s1_input_dim = 20531\n",
    "        self.s2_input_dim = 1046\n",
    "        \n",
    "        \n",
    "        ### layer 1 output dimension for omic 1, omic 2, omic 3 and omic 123\n",
    "        self.l1_s1_out_dim = 128\n",
    "        self.l1_s2_out_dim = 1024\n",
    "        \n",
    "        self.l2_s12_out_dim = 128\n",
    "        self.l3_s12_out_dim = 1024\n",
    "        \n",
    "        self.common_embed_dim = 256\n",
    "        \n",
    "        \n",
    "        super(X_AE_Encoder, self).__init__()\n",
    "        \n",
    "        ### encoder structure:\n",
    "        \n",
    "        ### first layer\n",
    "        self.l1_s1 = nn.Linear(self.s1_input_dim, self.l1_s1_out_dim)\n",
    "        self.l1_s1_bn = nn.BatchNorm1d(self.l1_s1_out_dim)\n",
    "        l1_s1_drop_rate = 0\n",
    "        self.drop_l1_s1 = nn.Dropout(p=l1_s1_drop_rate)\n",
    "        \n",
    "        \n",
    "        self.l1_s2 = nn.Linear(self.s2_input_dim, self.l1_s2_out_dim)\n",
    "        self.l1_s2_bn = nn.BatchNorm1d(self.l1_s2_out_dim)\n",
    "        l1_s2_drop_rate = 0\n",
    "        self.drop_l1_s2 = nn.Dropout(p=l1_s2_drop_rate)\n",
    "        \n",
    "        \n",
    "        self.l2_s12 = nn.Linear(self.l1_s1_out_dim + self.l1_s2_out_dim,\n",
    "                                 self.l2_s12_out_dim)\n",
    "        self.l2_s12_bn = nn.BatchNorm1d(self.l2_s12_out_dim)\n",
    "        l2_s12_drop_rate = 0.2\n",
    "        self.drop_l2_s12 = nn.Dropout(p=l2_s12_drop_rate)\n",
    "        \n",
    "        \n",
    "        self.l3_s12 = nn.Linear(self.l2_s12_out_dim,  self.l3_s12_out_dim)\n",
    "        self.l3_s12_bn = nn.BatchNorm1d(self.l3_s12_out_dim)\n",
    "        l3_s12_drop_rate = 0.4\n",
    "        self.drop_l3_s12 = nn.Dropout(p=l3_s12_drop_rate)\n",
    "        \n",
    "        \n",
    "        ## embedding layer\n",
    "        self.embed_s12 = nn.Linear(self.l3_s12_out_dim, self.common_embed_dim)\n",
    "        self.embed_s12_bn = nn.BatchNorm1d(self.common_embed_dim)\n",
    "        embed_s12_drop_rate = 0\n",
    "        self.drop_embed_s12 = nn.Dropout(p=embed_s12_drop_rate)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, s1, s2, labels=None):\n",
    "        \n",
    "        s1_ = self.drop_l1_s1(self.l1_s1_bn(F.relu(self.l1_s1(s1))))\n",
    "        s2_ = self.drop_l1_s2(self.l1_s2_bn(F.relu(self.l1_s2(s2))))\n",
    "        \n",
    "        s12_ = torch.cat((s1_, s2_), dim=1)\n",
    "        \n",
    "        s12_ = self.drop_l2_s12(self.l2_s12_bn(F.relu(self.l2_s12(s12_))))\n",
    "        s12_ = self.drop_l3_s12(self.l3_s12_bn(F.relu(self.l3_s12(s12_))))\n",
    "        \n",
    "        z12 = self.drop_embed_s12(self.embed_s12_bn(F.relu(self.embed_s12(s12_))))\n",
    "        \n",
    "        return z12, labels\n",
    "        \n",
    "\n",
    "class X_AE_Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.s1_input_dim = X_AE_Encoder().s1_input_dim\n",
    "        self.s2_input_dim = X_AE_Encoder().s2_input_dim\n",
    "        self.common_embed_dim = X_AE_Encoder().common_embed_dim\n",
    "        \n",
    "        \n",
    "        self._embed_s1_out_dim = 64\n",
    "        self._l3_s1_out_dim = 128\n",
    "        self._l2_s1_out_dim = 1024\n",
    "        self._l1_s1_out_dim = self.s1_input_dim\n",
    "        \n",
    "        \n",
    "        self._embed_s2_out_dim = 256\n",
    "        self._l3_s2_out_dim = 1024\n",
    "        self._l2_s2_out_dim = 32\n",
    "        self._l1_s2_out_dim = self.s2_input_dim\n",
    "        \n",
    "        \n",
    "        super(X_AE_Decoder, self).__init__()\n",
    "        \n",
    "        \n",
    "        self._embed_s1 = nn.Linear(self.common_embed_dim, self._embed_s1_out_dim)\n",
    "        self._embed_s1_bn = nn.BatchNorm1d(self._embed_s1_out_dim)\n",
    "        _embed_s1_drop_rate = 0.2\n",
    "        self._drop_embed_s1 = nn.Dropout(p=_embed_s1_drop_rate)\n",
    "        \n",
    "        \n",
    "        self._l3_s1 = nn.Linear(self._embed_s1_out_dim, self._l3_s1_out_dim)\n",
    "        self._l3_s1_bn = nn.BatchNorm1d(self._l3_s1_out_dim)\n",
    "        _l3_s1_drop_rate = 0.6\n",
    "        self._drop_l3_s1 = nn.Dropout(p=_l3_s1_drop_rate)\n",
    "        \n",
    "        \n",
    "        self._l2_s1 = nn.Linear(self._l3_s1_out_dim, self._l2_s1_out_dim)\n",
    "        self._l2_s1_bn = nn.BatchNorm1d(self._l2_s1_out_dim)\n",
    "        _l2_s1_drop_rate = 0\n",
    "        self._drop_l2_s1 = nn.Dropout(p=_l2_s1_drop_rate)\n",
    "        \n",
    "        \n",
    "        self._l1_s1 = nn.Linear(self._l2_s1_out_dim, self._l1_s1_out_dim)\n",
    "        self._l1_s1_bn = nn.BatchNorm1d(self._l1_s1_out_dim)\n",
    "        _l1_s1_drop_rate = 0\n",
    "        self._drop_l1_s1 = nn.Dropout(p=_l1_s1_drop_rate)\n",
    "        \n",
    "        \n",
    "        #############################################################################\n",
    "\n",
    "        self._embed_s2 = nn.Linear(self.common_embed_dim, self._embed_s2_out_dim)\n",
    "        self._embed_s2_bn = nn.BatchNorm1d(self._embed_s2_out_dim)\n",
    "        _embed_s2_drop_rate = 0.1\n",
    "        self._drop_embed_s2 = nn.Dropout(p=_embed_s2_drop_rate)\n",
    "        \n",
    "        \n",
    "        self._l3_s2 = nn.Linear(self._embed_s2_out_dim, self._l3_s2_out_dim)\n",
    "        self._l3_s2_bn = nn.BatchNorm1d(self._l3_s2_out_dim)\n",
    "        _l3_s2_drop_rate = 0.6\n",
    "        self._drop_l3_s2 = nn.Dropout(p=_l3_s2_drop_rate)\n",
    "        \n",
    "        \n",
    "        self._l2_s2 = nn.Linear(self._l3_s2_out_dim, self._l2_s2_out_dim)\n",
    "        self._l2_s2_bn = nn.BatchNorm1d(self._l2_s2_out_dim)\n",
    "        _l2_s2_drop_rate = 0.4\n",
    "        self._drop_l2_s2 = nn.Dropout(p=_l2_s2_drop_rate)\n",
    "        \n",
    "        \n",
    "        self._l1_s2 = nn.Linear(self._l2_s2_out_dim, self._l1_s2_out_dim)\n",
    "        self._l1_s2_bn = nn.BatchNorm1d(self._l1_s2_out_dim)\n",
    "        _l1_s2_drop_rate = 0.1\n",
    "        self._drop_l1_s2 = nn.Dropout(p=_l1_s2_drop_rate)\n",
    "        \n",
    "\n",
    "    def forward(self, z12):\n",
    "        \n",
    "        s1_ = self._drop_embed_s1(self._embed_s1_bn(F.relu(self._embed_s1(z12))))\n",
    "        s1_ = self._drop_l3_s1(self._l3_s1_bn(F.relu(self._l3_s1(s1_))))\n",
    "        s1_ = self._drop_l2_s1(self._l2_s1_bn(F.relu(self._l2_s1(s1_))))\n",
    "        s1_ = self._drop_l1_s1(self._l1_s1_bn(F.relu(self._l1_s1(s1_))))\n",
    "        \n",
    "        s1_out = torch.sigmoid(s1_)\n",
    "        \n",
    "        \n",
    "        s2_ = self._drop_embed_s2(self._embed_s2_bn(F.relu(self._embed_s2(z12))))\n",
    "        s2_ = self._drop_l3_s2(self._l3_s2_bn(F.relu(self._l3_s2(s2_))))\n",
    "        s2_ = self._drop_l2_s2(self._l2_s2_bn(F.relu(self._l2_s2(s2_))))\n",
    "        s2_ = self._drop_l1_s2(self._l1_s2_bn(F.relu(self._l1_s2(s2_))))\n",
    "        \n",
    "        s2_out = torch.sigmoid(s2_)\n",
    "        \n",
    "        \n",
    "        return s1_out, s2_out\n",
    "        \n",
    "    \n",
    "class X_AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(X_AE, self).__init__()\n",
    "        \n",
    "        self.encoder = X_AE_Encoder()\n",
    "        \n",
    "        self.decoder = X_AE_Decoder()\n",
    "\n",
    "    def forward(self, s1, s2, labels):\n",
    "        ### encoder ouput for embeddings \n",
    "        z12, labels = self.encoder(s1, s2, labels)\n",
    "        ### decoder output for reconstructed input\n",
    "        s1_out, s2_out = self.decoder(z12)\n",
    "        return z12, s1_out, s2_out, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f515b357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X_AE(\n",
       "  (encoder): X_AE_Encoder(\n",
       "    (l1_s1): Linear(in_features=20531, out_features=128, bias=True)\n",
       "    (l1_s1_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop_l1_s1): Dropout(p=0, inplace=False)\n",
       "    (l1_s2): Linear(in_features=1046, out_features=1024, bias=True)\n",
       "    (l1_s2_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop_l1_s2): Dropout(p=0, inplace=False)\n",
       "    (l2_s12): Linear(in_features=1152, out_features=128, bias=True)\n",
       "    (l2_s12_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop_l2_s12): Dropout(p=0.2, inplace=False)\n",
       "    (l3_s12): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (l3_s12_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop_l3_s12): Dropout(p=0.4, inplace=False)\n",
       "    (embed_s12): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (embed_s12_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop_embed_s12): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (decoder): X_AE_Decoder(\n",
       "    (_embed_s1): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (_embed_s1_bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (_drop_embed_s1): Dropout(p=0.2, inplace=False)\n",
       "    (_l3_s1): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (_l3_s1_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (_drop_l3_s1): Dropout(p=0.6, inplace=False)\n",
       "    (_l2_s1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (_l2_s1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (_drop_l2_s1): Dropout(p=0, inplace=False)\n",
       "    (_l1_s1): Linear(in_features=1024, out_features=20531, bias=True)\n",
       "    (_l1_s1_bn): BatchNorm1d(20531, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (_drop_l1_s1): Dropout(p=0, inplace=False)\n",
       "    (_embed_s2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (_embed_s2_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (_drop_embed_s2): Dropout(p=0.1, inplace=False)\n",
       "    (_l3_s2): Linear(in_features=256, out_features=1024, bias=True)\n",
       "    (_l3_s2_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (_drop_l3_s2): Dropout(p=0.6, inplace=False)\n",
       "    (_l2_s2): Linear(in_features=1024, out_features=32, bias=True)\n",
       "    (_l2_s2_bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (_drop_l2_s2): Dropout(p=0.4, inplace=False)\n",
       "    (_l1_s2): Linear(in_features=32, out_features=1046, bias=True)\n",
       "    (_l1_s2_bn): BatchNorm1d(1046, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (_drop_l1_s2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_AE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f4367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomLoss(s1, s2, s1_out, s2_out,\n",
    "                z12, labels, z1=None, z2=None):\n",
    "    #         self.alpha = alpha\n",
    "\n",
    "    ### subtract the mean \n",
    "\n",
    "#     s1_out = s1_out - s1_out.mean()\n",
    "#     s2_out = s2_out - s2_out.mean()\n",
    "    \n",
    "    ### normalize the feature vector with length 1\n",
    "    s1_out = F.normalize(s1_out, p=2, dim=1)\n",
    "    s2_out = F.normalize(s2_out, p=2, dim=1)\n",
    "    \n",
    "    \n",
    "#     s1 = s1 - s1.mean()\n",
    "#     s2 = s2 - s2.mean()\n",
    "    s1 = F.normalize(s1, p=2, dim=1)\n",
    "    s2 = F.normalize(s2, p=2, dim=1)\n",
    "\n",
    "    recon_loss = torch.linalg.matrix_norm(s1_out-s1) + torch.linalg.matrix_norm(s2_out-s2)\n",
    "\n",
    "    return recon_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec37dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### assuming all the hyperparameters are optimized by Optuna and then retrain the model on the entire training set\n",
    "\n",
    "def retraining(model, dataset, model_folder):\n",
    "    \n",
    "    train_recon_loss_ = []\n",
    "\n",
    "    device = torch.device('cuda:1') if torch. cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    batch_size = 256\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "#     print(len(train_loader))\n",
    "    \n",
    "    model = model().to(device=device)\n",
    "#     print(model)\n",
    "    \n",
    "    \n",
    "    optimizer_name = 'Adam'\n",
    "    lr = 0.009879554857102159\n",
    "    l2_lambda = 7.987530040843315e-06\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=l2_lambda)\n",
    "    \n",
    "    epochs = 120 ### reduce the epochs from 150 to 100 to reduce the potential overfitting\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        #         print(f\"I'am in the epoch {epoch}\")\n",
    "        model.train()\n",
    "        # record the training loss\n",
    "        total_recon_loss = 0.0\n",
    "        total_train = 0.0\n",
    "\n",
    "        ## deal with different number of features in different dataset with star* notation\n",
    "        for view1_train_data, view2_train_data, train_labels in train_loader:\n",
    "            ### this line is just for nn.CrossEntropy loss otherwise can be safely removed\n",
    "            view1_train_data = view1_train_data.type(torch.float32).to(device)\n",
    "            view2_train_data = view2_train_data.type(torch.float32).to(device)\n",
    "            train_labels = train_labels.type(torch.LongTensor).to(device)\n",
    "\n",
    "            z12, s1_out, s2_out, labels = \\\n",
    "            model(view1_train_data, view2_train_data, train_labels)\n",
    "            \n",
    "            train_size = z12.size()[0]\n",
    "    \n",
    "            recon_loss = CustomLoss(s1=view1_train_data,\\\n",
    "                                             s2=view2_train_data,\\\n",
    "                                             s1_out=s1_out,\\\n",
    "                                             s2_out=s2_out,\\\n",
    "                                             z12=z12,\\\n",
    "                                             labels=train_labels)\n",
    "            loss = recon_loss\n",
    "\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()  # empty the gradient from last round\n",
    "\n",
    "            # calculate the gradient\n",
    "            loss.backward()\n",
    "            # update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train += train_size\n",
    "            \n",
    "            total_recon_loss += recon_loss.item()\n",
    "    \n",
    "        train_recon_loss_.append(total_recon_loss / total_train)\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'finished retraining on epoch: {epoch}')\n",
    "    # save the model at the end of 150 epochs\n",
    "    model_path = f\"{model_folder}/retrained_model_{epoch}.pt\"\n",
    "    \n",
    "    torch.save(model, model_path)\n",
    "    \n",
    "    return train_recon_loss_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d5e05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_retraining():\n",
    "    ### where to save the 3-fold CV validation acc\n",
    "\n",
    "    ### where to save the retrained model\n",
    "    model_folder = '/home/wangc90/Data_integration/TCGA_model_outputs/model_retraining_outputs/X_AE_retraining'\n",
    "\n",
    "    combined_exp_df = pd.read_csv('/home/wangc90/Data_integration/TCGA_data/TCGA_primary_tumor_data/combined_exp_df.csv', sep='\\t')\n",
    "    combined_miRNA_df = pd.read_csv('/home/wangc90/Data_integration/TCGA_data/TCGA_primary_tumor_data/combined_miRNA_df.csv', sep='\\t')\n",
    "\n",
    "    labels = pd.read_csv('/home/wangc90/Data_integration/TCGA_data/TCGA_primary_tumor_data/labels.csv', sep='\\t')['0']\n",
    "\n",
    "    dataset_prep = DataSet_Prep(data1=combined_exp_df, data2=combined_miRNA_df, label=labels, training_prop=0.8)\n",
    "\n",
    "    train_key, test_key = dataset_prep.get_train_test_keys()\n",
    "\n",
    "    feature1_tensors, feature2_tensors, label_tensors = dataset_prep.to_tensor(train_key)\n",
    "    \n",
    "\n",
    "    train_dataset = DataSet_construction(feature1_tensors, feature2_tensors, label_tensors)\n",
    "\n",
    "    print(len(train_dataset))\n",
    "\n",
    "    train_recon_loss_ = retraining(model=X_AE, dataset=train_dataset,model_folder=model_folder)\n",
    "    \n",
    "    return train_recon_loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456abea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1 and feature2 are being scaled with MinMaxScaler\n",
      "1494\n",
      "finished retraining on epoch: 9\n",
      "finished retraining on epoch: 19\n",
      "finished retraining on epoch: 29\n",
      "finished retraining on epoch: 39\n",
      "finished retraining on epoch: 49\n",
      "finished retraining on epoch: 59\n",
      "finished retraining on epoch: 69\n",
      "finished retraining on epoch: 79\n",
      "finished retraining on epoch: 89\n",
      "finished retraining on epoch: 99\n",
      "finished retraining on epoch: 109\n",
      "finished retraining on epoch: 119\n"
     ]
    }
   ],
   "source": [
    "train_recon_loss_ = X_retraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed74a484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_recon_loss_, label='train_recon_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0b3d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
